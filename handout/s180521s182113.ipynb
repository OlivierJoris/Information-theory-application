{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Project 1 - Information measures\n",
    "\n",
    "The goal of this first project is to get accustomed to the information and uncertainty measures. We ask you to write a brief report (pdf format) collecting your answers to the different questions. All codes must be written in Python inside this Jupyter Notebook. No other code file will be accepted. Note that you can not change the content of locked cells or import any extra Python library than the ones already imported (numpy and pandas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Implementation\n",
    "\n",
    "In this project, you will need to use information measures to answer several questions. Therefore, in this first part, you are asked to write several functions that implement some of the main measures seen in the first theoretical lectures. Remember that you need to fill in this Jupyter Notebook to answer these questions. Pay particular attention to the required output format of each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# [Locked Cell] You can not import any extra Python library in this Notebook.\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Write a function entropy that computes the entropy $\\mathcal{H(X)}$ of a random variable $\\mathcal{X}$ from its probability distribution $P_\\mathcal{X} = (p_1, p_2, . . . , p_n)$. Give the mathematical formula that you are using and explain the key parts of your implementation. Intuitively, what is measured by the entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(Px):\n",
    "    \"\"\"\n",
    "    Computes the entropy from the marginal probability distribution. \n",
    "    Arguments:\n",
    "    ----------\n",
    "    - Px :  Marginal probability distribution of the random \n",
    "            variable X in a numpy array where Px[i]=P(X=i)\n",
    "    Return:\n",
    "    -------\n",
    "    - The entropy of X (H(X)) as a number (integer, float or double).\n",
    "    \"\"\"\n",
    "    # Only take non-negative values because log(x) is defined on ] 0, + inf. [ \n",
    "    nonNegativePx = Px[Px > 0]\n",
    "    return -np.sum(nonNegativePx * np.log2(nonNegativePx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Write a function joint_entropy that computes the joint entropy $\\mathcal{H(X,Y)}$ of two discrete random variables $\\mathcal{X}$ and $\\mathcal{Y}$ from the joint probability distribution $P_\\mathcal{X,Y}$. Give the mathematical formula that you are using and explain the key parts of your implementation. Compare the entropy and joint_entropy functions (and their corresponding formulas), what do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_entropy(Pxy):\n",
    "    \"\"\"\n",
    "    Computes the joint entropy from the joint probability distribution.  \n",
    "    Arguments:\n",
    "    ----------\n",
    "    - Pxy:  joint probability distribution of X and Y \n",
    "            in a 2-D numpy array where Pxy[i][j]=P(X=i,Y=j)\n",
    "    Return:\n",
    "    -------\n",
    "    - The joint entropy H(X,Y) as a number (integer, float or double).\n",
    "    \"\"\"\n",
    "    # Converts to one dimension\n",
    "    return entropy(Pxy.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Write a function conditional_entropy that computes the conditional entropy $\\mathcal{H(X|Y)}$ of a discrete random variable $\\mathcal{X}$ given another discrete random variable $\\mathcal{Y}$ from the joint probability distribution $P_\\mathcal{X,Y}$. Give the mathematical formula that you are using and explain the key parts of your implementation. Describe an equivalent way of computing that quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_entropy(Pxy):\n",
    "    \"\"\"\n",
    "    Computes the conditional entropy from the joint probability distribution.\n",
    "    Arguments:\n",
    "    ----------\n",
    "    - Pxy:  joint probability distribution of X and Y \n",
    "            in a 2-D numpy array where Pxy[i][j]=P(X=i,Y=j)\n",
    "    Return:\n",
    "    -------\n",
    "    - The conditional entropy H(X|Y) as a number (integer, float or double)\n",
    "    \"\"\"\n",
    "    Py = Pxy.sum(axis = 0)\n",
    "    return joint_entropy(Pxy) - entropy(Py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Write a function mutual_information that computes the mutual information $\\mathcal{I(X;Y)}$ between two discrete random variables $\\mathcal{X}$ and $\\mathcal{Y}$ from the joint probability distribution $P_\\mathcal{X,Y}$ . Give the mathematical formula that you are using and explain the key parts of your implementation. What can you deduce from the mutual information $\\mathcal{I(X;Y)}$ on the relationship between $\\mathcal{X}$ and $\\mathcal{Y}$? Discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(Pxy):\n",
    "    \"\"\"\n",
    "    Computes the mutual information I(X;Y) from joint probability distribution\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    - Pxy:  joint probability distribution of X and Y \n",
    "            in a 2-D numpy array where Pxy[i][j]=P(X=i,Y=j)\n",
    "    Return:\n",
    "    -------\n",
    "    - The mutual information I(X;Y) as a number (integer, float or double)\n",
    "    \"\"\"\n",
    "    Px = Pxy.sum(axis = 1)\n",
    "    return entropy(Px) - conditional_entropy(Pxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Let $\\mathcal{X}$, $\\mathcal{Y}$ and $\\mathcal{Z}$ be three discrete random variables. Write the functions cond_joint_entropy and cond_mutual_information that respectively compute $\\mathcal{H(X,Y|Z)}$ and $\\mathcal{I(X;Y|Z)}$ of two discrete random variable $\\mathcal{X}$, $\\mathcal{Y}$ given another discrete random variable $\\mathcal{Z}$ from their joint probability distribution $P_\\mathcal{X,Y,Z}$. Give the mathematical formulas that you are using and explain the key parts of your implementation.\n",
    "Suggestion: Observe the mathematical definitions of these quantities and think how you could derive them from the joint entropy and the mutual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_joint_entropy(Pxyz):\n",
    "    \"\"\"\n",
    "    Computes the conditional joint entropy of X, Y knowing Z \n",
    "    from the joint probability distribution Pxyz\n",
    "    Arguments:\n",
    "    ----------\n",
    "    - Pxyz: joint probability distribution of X, Y and Z\n",
    "            in a 3-D array where Pxyz[i][j][k]=P(X=i,Y=j,Z=k)\n",
    "    Return:\n",
    "    -------\n",
    "    - The conditional joint entropy H(X,Y|Z) as a number (integer, float or double)\n",
    "    \n",
    "    \"\"\"\n",
    "    Pz = Pxyz.sum(axis = (0, 1))\n",
    "    return joint_entropy(Pxyz) - entropy(Pz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_mutual_information(Pxyz):\n",
    "    \"\"\"\n",
    "    Computes the conditional mutual information of X, Y knowing Z \n",
    "    from joint probability distribution Pxyz\n",
    "    Arguments:\n",
    "    ----------\n",
    "    - Pxyz: joint probability distribution of X, Y and Z\n",
    "            in a 3-D array where Pxyz[i][j][k]=P(X=i,Y=j,Z=k)\n",
    "    Return:\n",
    "    -------\n",
    "    - I(X;Y|Z): The conditional joint entropy as a number (integer, float or double)\n",
    "    \n",
    "    \"\"\"\n",
    "    Pxz = Pxyz.sum(axis = 1)\n",
    "    Pyz = Pxyz.sum(axis = 0)\n",
    "    return conditional_entropy(Pxz) + joint_entropy(Pyz) - joint_entropy(Pxyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# [Locked Cell] Evaluation of your functions by the examiner. \n",
    "# You don't have access to the evaluation, this will be done by the examiner.\n",
    "# Therefore, this cell will return nothing for the students.\n",
    "import os\n",
    "if os.path.isfile(\"private_evaluation.py\"):\n",
    "    from private_evaluation import unit_tests\n",
    "    unit_tests(entropy, joint_entropy, conditional_entropy, mutual_information, cond_joint_entropy, cond_mutual_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Weather forecasting\n",
    "\n",
    "You may create cells below to answer the different questions related to weather forecasting. Unlike in the first part (Implementation), you are free to define as many cells as you need below to answer the different questions. Try to be structured and clear in your code (comment it if necessary). Note that you have to answer the questions in the pdf report, including the numbers you get!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency(variable):\n",
    "    \"\"\"\n",
    "    Computes the frequency distribution of a given variable of the dataset\n",
    "    Arguments:\n",
    "    ----------\n",
    "    - variable: the variable name\n",
    "    Return:\n",
    "    -------\n",
    "    - an array with the frequency distribution corresponding to the given variable\n",
    "    \"\"\"\n",
    "    return data[variable].value_counts(normalize = True).values\n",
    "\n",
    "def joint_frequency(*variables):\n",
    "    \"\"\"\n",
    "    Computes the joint frequency distribution of given variables of the dataset\n",
    "    Arguments:\n",
    "    ----------\n",
    "    - variable: the variable name\n",
    "    Return:\n",
    "    -------\n",
    "    - a numpy array with the joint frequency distribution corresponding to the \n",
    "      given variables\n",
    "    \"\"\"\n",
    "    if(len(variables) == 2):\n",
    "        firstVariableUnique = np.unique(variables[0])\n",
    "        secondVariableUnique = np.unique(variables[1])\n",
    "       \n",
    "        jointFrequency = np.zeros([len(firstVariableUnique), len(secondVariableUnique)])\n",
    "\n",
    "        for indexVar0, uniqueVar0 in enumerate(firstVariableUnique):\n",
    "            for indexVar1, uniqueVar1 in enumerate(secondVariableUnique):\n",
    "                for i in range(len(variables[0])):\n",
    "                    if variables[0][i] == uniqueVar0 and variables[1][i] == uniqueVar1:\n",
    "                        jointFrequency[indexVar0][indexVar1] += 1 / len(variables[0])\n",
    "\n",
    "        return jointFrequency\n",
    "    \n",
    "    elif(len(variables) == 3):\n",
    "        firstVariableUnique = np.unique(variables[0])\n",
    "        secondVariableUnique = np.unique(variables[1])\n",
    "        thirdVariableUnique = np.unique(variables[2])\n",
    "       \n",
    "        jointFrequency = np.zeros([len(firstVariableUnique), len(secondVariableUnique), len(thirdVariableUnique)])\n",
    "\n",
    "        for indexVar0, uniqueVar0 in enumerate(firstVariableUnique):\n",
    "            for indexVar1, uniqueVar1 in enumerate(secondVariableUnique):\n",
    "                for indexVar2, uniqueVar2 in enumerate(thirdVariableUnique):\n",
    "                    for i in range(len(variables[0])):\n",
    "                        if variables[0][i] == uniqueVar0 and variables[1][i] == uniqueVar1 and variables[2][i] == uniqueVar2:\n",
    "                            jointFrequency[indexVar0][indexVar1][indexVar2] += 1 / len(variables[0])\n",
    "\n",
    "        return jointFrequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('weather_data.csv')\n",
    "\n",
    "VARIABLES = { \n",
    "              'temperature': ['freezing', 'cold', 'medium', 'high'],\n",
    "              'air_pressure': ['increasing', 'decreasing'],\n",
    "              'same_day_rain': ['dry', 'drizzle', 'deluge'],\n",
    "              'next_day_rain': ['dry', 'drizzle', 'deluge'],\n",
    "              'relative_humidity': ['low', 'high'],\n",
    "              'wind_direction': ['north', 'south', 'east', 'west'],\n",
    "              'wind_speed': ['no_wind', 'low', 'high'],\n",
    "              'cloud_height': ['no_cloud', 'low', 'high'],\n",
    "              'cloud_density': ['no_cloud', 'low', 'high'],\n",
    "              'month': ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december'],\n",
    "              'day': ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday'],\n",
    "              'daylight': ['sunny', 'cloudy'],\n",
    "              'lightning': ['no_lightning', 'low', 'high'],\n",
    "              'air_quality': ['bad', 'medium', 'good']\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 6:\n",
      "\n",
      "temperature: entropy: 1.5113935187 cardinality: 4\n",
      "air_pressure: entropy: 0.9999971146 cardinality: 2\n",
      "same_day_rain: entropy: 1.4754687972 cardinality: 3\n",
      "next_day_rain: entropy: 1.5686562064 cardinality: 3\n",
      "relative_humidity: entropy: 0.9997963973 cardinality: 2\n",
      "wind_direction: entropy: 1.9995507337 cardinality: 4\n",
      "wind_speed: entropy: 1.5848180055 cardinality: 3\n",
      "cloud_height: entropy: 1.5846220676 cardinality: 3\n",
      "cloud_density: entropy: 1.5844638107 cardinality: 3\n",
      "month: entropy: 3.5834131971 cardinality: 12\n",
      "day: entropy: 2.8063989677 cardinality: 7\n",
      "daylight: entropy: 0.9986283124 cardinality: 2\n",
      "lightning: entropy: 0.3249678888 cardinality: 3\n",
      "air_quality: entropy: 0.5358803476 cardinality: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 6:\\n\")\n",
    "\n",
    "for variable in VARIABLES:\n",
    "    freq = frequency(variable)\n",
    "    print(\"{}: {}: {:.10f} {}: {}\".format(variable,'entropy', entropy(freq), 'cardinality', len(VARIABLES[variable])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 7:\n",
      "\n",
      "next_day_rain, temperature: 1.5681010090\n",
      "next_day_rain, air_pressure: 0.9399751579\n",
      "next_day_rain, same_day_rain: 1.3894855511\n",
      "next_day_rain, relative_humidity: 1.3010552471\n",
      "next_day_rain, wind_direction: 1.5678153355\n",
      "next_day_rain, wind_speed: 1.5677670878\n",
      "next_day_rain, cloud_height: 1.5667630290\n",
      "next_day_rain, cloud_density: 1.5665898847\n",
      "next_day_rain, month: 1.5648797492\n",
      "next_day_rain, day: 1.5671568099\n",
      "next_day_rain, daylight: 1.5682591877\n",
      "next_day_rain, lightning: 1.5682325749\n",
      "next_day_rain, air_quality: 1.5678811342\n"
     ]
    }
   ],
   "source": [
    "print('Question 7:\\n')\n",
    "\n",
    "nextDayRainValues = data['next_day_rain'].values\n",
    "\n",
    "for variable in VARIABLES:\n",
    "    if variable != 'next_day_rain':\n",
    "        variableValues = data[variable].values\n",
    "        jointFreq = joint_frequency(nextDayRainValues, variableValues)\n",
    "\n",
    "        if len(jointFreq.shape) != 2:\n",
    "            print('Error while computing the joint frequency of next_day_rain and {}'.format(variable))\n",
    "        \n",
    "        print('next_day_rain, {}: {:.10f}'.format(variable, conditional_entropy(jointFreq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 8:\n",
      "\n",
      "Mutual information between relative_humidity and wind_speed: 0.0001243960\n",
      "Mutual information between month and temperature: 0.5753467937\n"
     ]
    }
   ],
   "source": [
    "print('Question 8:\\n')\n",
    "\n",
    "relativeHumidityValues = data['relative_humidity'].values\n",
    "windSpeedValues = data['wind_speed'].values\n",
    "jointFreq = joint_frequency(relativeHumidityValues, windSpeedValues)\n",
    "if len(jointFreq.shape) != 2:\n",
    "    print('Error while computing the joint frequency of relative_humidity and wind_speed')\n",
    "\n",
    "print('Mutual information between relative_humidity and wind_speed: {:.10f}'.format(mutual_information(jointFreq)))\n",
    "\n",
    "monthValues = data['month'].values\n",
    "temperatureValues = data['temperature'].values\n",
    "jointFreq = joint_frequency(monthValues, temperatureValues)\n",
    "if len(jointFreq.shape) != 2:\n",
    "    print('Error while computing the joint frequency of month and temperature')\n",
    "\n",
    "print('Mutual information between month and temperature: {:.10f}'.format(mutual_information(jointFreq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 9:\n",
      "\n",
      "The instrument kept which has the highest mutual information with next_day_rain is air_pressure (0.6286810485).\n",
      "\n",
      "The instrument kept which has the lowest conditional entropy with next_day_rain is air_pressure (0.9399751579).\n"
     ]
    }
   ],
   "source": [
    "print('Question 9:\\n')\n",
    "\n",
    "nextDayRainValues = data['next_day_rain'].values\n",
    "mutual_informations = {}\n",
    "conditional_entropies = {}\n",
    "\n",
    "for variable in VARIABLES:\n",
    "    if variable != 'next_day_rain':\n",
    "        variableValues = data[variable].values\n",
    "        jointFreq = joint_frequency(nextDayRainValues, variableValues)\n",
    "\n",
    "        if len(jointFreq.shape) != 2:\n",
    "            print('Error while computing the joint frequency of next_day_rain and {}'.format(variable))\n",
    "\n",
    "        mutual_informations[variable] = mutual_information(jointFreq)\n",
    "        conditional_entropies[variable] = conditional_entropy(jointFreq)\n",
    "\n",
    "print('The instrument kept which has the highest mutual information with next_day_rain is {} ({:.10f}).\\n'.format(max(mutual_informations, key = mutual_informations.get), max(mutual_informations.values())))\n",
    "print('The instrument kept which has the lowest conditional entropy with next_day_rain is {} ({:.10f}).'.format(min(conditional_entropies, key = conditional_entropies.get), min(conditional_entropies.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 10:\n",
      "\n",
      "The instrument kept which has the highest mutual information with next_day_rain is relative_humidity (0.4391920975).\n",
      "\n",
      "The instrument kept which has the lowest conditional entropy with next_day_rain is relative_humidity (0.5601193454).\n"
     ]
    }
   ],
   "source": [
    "print('Question 10:\\n')\n",
    "\n",
    "dataQ10 = data.drop(data.loc[data['next_day_rain'] == 'dry'].index, inplace = False)\n",
    "\n",
    "nextDayRainValues = dataQ10['next_day_rain'].values\n",
    "mutual_informations = {}\n",
    "conditional_entropies = {}\n",
    "\n",
    "for variable in VARIABLES:\n",
    "    if variable != 'next_day_rain':\n",
    "        variableValues = dataQ10[variable].values\n",
    "        jointFreq = joint_frequency(nextDayRainValues,variableValues)\n",
    "\n",
    "        if len(jointFreq.shape) != 2:\n",
    "            print('Error while computing the joint frequency of next_day_rain and {}'.format(variable))\n",
    "\n",
    "        mutual_informations[variable] = mutual_information(jointFreq)\n",
    "        conditional_entropies[variable] = conditional_entropy(jointFreq)\n",
    "\n",
    "print('The instrument kept which has the highest mutual information with next_day_rain is {} ({:.10f}).\\n'.format(max(mutual_informations, key = mutual_informations.get), max(mutual_informations.values())))\n",
    "print('The instrument kept which has the lowest conditional entropy with next_day_rain is {} ({:.10f}).'.format(min(conditional_entropies, key = conditional_entropies.get), min(conditional_entropies.values())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 11:\n",
      "\n",
      "The instrument kept which has the highest conditional mutual information with next_day_rain knowing temperature is air_pressure (0.6294687900).\n",
      "\n",
      "The instrument which leads to the lowest conditional entropy of next_day_rain knowing temperature and this variable is air_pressure (0.9386322190).\n"
     ]
    }
   ],
   "source": [
    "print('Question 11:\\n')\n",
    "\n",
    "nextDayRainValues = data['next_day_rain'].values\n",
    "temperatureValues = data['temperature'].values\n",
    "mutual_informations = {}\n",
    "conditional_entropies = {}\n",
    "\n",
    "for variable in VARIABLES:\n",
    "    if variable != 'next_day_rain' and variable != 'temperature':\n",
    "        variableValues = data[variable].values\n",
    "\n",
    "        jointFreqThree = joint_frequency(nextDayRainValues, variableValues, temperatureValues)\n",
    "        if len(jointFreqThree.shape) != 3:\n",
    "            print('Error while computing the joint frequency of next_day_rain, temperature, and {}'.format(variable))\n",
    "\n",
    "        jointFreqTwo = joint_frequency(variableValues, temperatureValues)\n",
    "        if len(jointFreqTwo.shape) != 2:\n",
    "            print('Error while computing the joint frequency of {} and temperature'.format(variable))\n",
    "        \n",
    "        mutual_informations[variable] = cond_mutual_information(jointFreqThree)\n",
    "        conditional_entropies[variable] = cond_joint_entropy(jointFreqThree) - conditional_entropy(jointFreqTwo)  \n",
    "\n",
    "print('The instrument kept which has the highest conditional mutual information with next_day_rain knowing temperature is {} ({:.10f}).\\n'.format(max(mutual_informations, key = mutual_informations.get), max(mutual_informations.values())))\n",
    "print('The instrument which leads to the lowest conditional entropy of next_day_rain knowing temperature and this variable is {} ({:.10f}).'.format(min(conditional_entropies, key = conditional_entropies.get), min(conditional_entropies.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Entropy of the one of the gray field and the whole game after the 2 first guesses using TABLE and ROUGH (code used to answer question 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entropy of one of the gray fields after the second guess is equal to 3.5827297607 bits.\n",
      "The entropy of the game after the second guess is equal to 13.9313838925 bits.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import math\n",
    "\n",
    "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "# Generates the permutations. \n",
    "words = [p for p in itertools.product(letters, repeat = 5)]\n",
    "\n",
    "possibleWords = []\n",
    "\n",
    "# Finds the amount of possible words according to the indications of the game.\n",
    "for word in words:\n",
    "    if word[3] != 'g' and word[1] == 'a' and not 't' in word and not 'b' in word and not 'l' in word and not 'e' in word and not 'r' in word and not 'o' in word and not 'u' in word and not 'h' in word and 'g' in word:\n",
    "        possibleWords.append(word)\n",
    "\n",
    "probaGrayLetter = {}\n",
    "\n",
    "# Marginalizes to find the probability distribution of one of the gray fields (1st, 3rd and 5th field).\n",
    "for letter in letters:\n",
    "    probaGrayLetter[letter] = 0\n",
    "\n",
    "for word in possibleWords:\n",
    "    probaGrayLetter[word[0]] += 1 / len(possibleWords)\n",
    "\n",
    "probaGrayDistribution = np.array(list(probaGrayLetter.values()))\n",
    "grayFieldEntropy = entropy(probaGrayDistribution)\n",
    "\n",
    "print('The entropy of one of the gray fields after the second guess is equal to {:.10f} bits.'.format(grayFieldEntropy))\n",
    "\n",
    "print('The entropy of the game after the second guess is equal to {:.10f} bits.'.format(math.log2(len(possibleWords))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
